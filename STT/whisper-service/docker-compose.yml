version: '3.8'

services:
  whisper-stt:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        WHISPER_MODEL: large-v3-turbo
    ports:
      - "8000:8000"
    environment:
      - STT_HOST=0.0.0.0
      - STT_PORT=8000
      - STT_WHISPER_MODEL=large-v3-turbo
      - STT_COMPUTE_TYPE=float16
      - STT_DEVICE=cuda
      - STT_LANGUAGE=pt
      - STT_VAD_ENABLED=true
      - STT_VAD_THRESHOLD=0.5
      - STT_PARTIAL_INTERVAL_MS=300
      - STT_MAX_QUEUE_DEPTH=20
      - STT_LOG_LEVEL=INFO
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 120s
    restart: unless-stopped
